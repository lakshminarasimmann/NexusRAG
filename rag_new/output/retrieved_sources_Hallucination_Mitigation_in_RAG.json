[
  {
    "title": "Mitigating Hallucination in Large Language Models LLMs An Application-Oriented Survey on RAG Reasoning and Agentic Systems.pdf",
    "chunk": "Mitigation therefore focuses on supplementing the model with\naccurate and relevant external knowledg..."
  },
  {
    "title": "Mitigating Hallucination in Large Language Models LLMs An Application-Oriented Survey on RAG Reasoning and Agentic Systems.pdf",
    "chunk": "1\nMitigating Hallucination in Large Language Models\n(LLMs): An Application-Oriented Survey on RAG,\nR..."
  },
  {
    "title": "Attribution Techniques for Mitigating Hallucinated Information in RAG Systems A Survey.pdf",
    "chunk": "links specific types of hallucination to appropriate\nmitigation strategies. This survey addresses th..."
  },
  {
    "title": "Mitigating Hallucination in Large Language Models LLMs An Application-Oriented Survey on RAG Reasoning and Agentic Systems.pdf",
    "chunk": "IX. Conclusion\nThis survey adopts an application-oriented perspective of\ncapability enhancement to s..."
  },
  {
    "title": "Mitigating Hallucination in Large Language Models LLMs An Application-Oriented Survey on RAG Reasoning and Agentic Systems.pdf",
    "chunk": "Future research should pursue a systematic and layered\nhallucination mitigation framework that integ..."
  }
]